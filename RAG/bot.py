import os, uuid, hashlib, datetime, tempfile, json
from io import BytesIO
import psycopg2, fitz, pytesseract
from PIL import Image
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import ApplicationBuilder, MessageHandler, ContextTypes, filters
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI

# ---------- åŸºç¤è¨­å®š --------------------------------------------------------
load_dotenv()
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
IMAGE_DIR  = "image_dir"; os.makedirs(IMAGE_DIR, exist_ok=True)

embedding_model = OpenAIEmbeddings(
    model="text-embedding-3-small",
    api_key=os.getenv("OPENAI_API_KEY")
)
llm = ChatOpenAI(model="gpt-5", temperature=1)

STRICT_SYS_PROMPT = """1. åªå¼•ç”¨ä¾†æºèƒ½æ”¯æŒçš„å…§å®¹ï¼›ä¸å¯å¤–éƒ¨å¸¸è­˜å»¶ä¼¸ã€‚
2. æ¯ä¸€å¥è©±å¾Œé¢éƒ½å¿…é ˆåŠ ä¸Š [doc_id:æ®µè½æˆ–é ç¢¼] å¼•ç”¨ï¼›è‹¥æ²’æœ‰è¶³å¤ ä¾†æºï¼Œå°±ä¸å›ç­”ã€‚
3. ç¦æ­¢ä½¿ç”¨ä¾†æºæœªå‡ºç¾çš„æ•¸å­—ã€åè©å®šç¾©èˆ‡çµè«–ã€‚
4. ç¦æ­¢æ”¹å¯«æˆèˆ‡åŸæ„çŸ›ç›¾çš„èªªæ³•ï¼›å°å°ˆæœ‰åè©ä¿ç•™åŸæ–‡ã€‚"""


PG_CONF = dict(
    host=os.environ["PG_HOST"],
    port=os.environ["PG_PORT"],
    dbname=os.environ["PG_DB"],
    user=os.environ["PG_USER"],
    password=os.environ["PG_PASSWORD"]
)

# ---- ç›¸ä¼¼åº¦é–€æª»ï¼ˆcosine distanceï¼›è¶Šå°è¶Šåƒï¼‰ -------------------------------
IMG_SIM_THRESHOLD = float(os.getenv("IMG_SIM_THRESHOLD", "0.75"))
IMG_TOPK = int(os.getenv("IMG_TOPK", "5"))

# ---------- å…±ç”¨å°å‡½å¼ ------------------------------------------------------
def db_conn():
    return psycopg2.connect(**PG_CONF)

def vector_to_str(vec):
    return "[" + ",".join(f"{v:.8f}" for v in vec) + "]"

def insert_pdf_text(cur, content, filename):
    vec_str = vector_to_str(embedding_model.embed_query(content))
    cur.execute("""
        INSERT INTO documents (content, embedding, source_type,
                               filename, upload_time)
        VALUES (%s,%s,'pdf_text',%s,%s)
    """, (content, vec_str, filename, datetime.datetime.utcnow()))

def save_image_and_insert(cur, img_bytes, ocr_text,
                          source_type, filename, page_num=None):
    # è¨ˆç®— hashï¼Œè‹¥é‡è¤‡å°±ç•¥é
    img_hash = hashlib.md5(img_bytes).hexdigest()
    cur.execute("SELECT 1 FROM documents WHERE image_hash=%s", (img_hash,))
    if cur.fetchone():
        return

    image_ref = f"{uuid.uuid4().hex}_{filename}"
    img_path  = os.path.join(IMAGE_DIR, image_ref)
    with open(img_path, "wb") as f: f.write(img_bytes)

    vec_str = None
    if ocr_text:
        vec_str = vector_to_str(embedding_model.embed_query(ocr_text))

    cur.execute("""
        INSERT INTO documents (content, embedding, source_type,
                               filename, page_num,
                               image_ref, image_hash, upload_time)
        VALUES (%s,%s,%s,%s,%s,%s,%s,%s)
    """, (ocr_text or None, vec_str, source_type,
          filename, page_num,
          image_ref, img_hash, datetime.datetime.utcnow()))

# ---------- PDF ä¸Šå‚³è™•ç† ----------------------------------------------------
async def process_pdf(file_path):
    filename  = os.path.basename(file_path)
    loader    = PyPDFLoader(file_path)
    pdf_doc   = fitz.open(file_path)
    splitter  = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=200)

    with db_conn() as conn:
        with conn.cursor() as cur:
            # æ–‡å­—åˆ†æ®µ
            for doc in splitter.split_documents(loader.load()):
                if doc.page_content.strip():
                    insert_pdf_text(cur, doc.page_content.strip(), filename)

            # åœ–ç‰‡ OCR
            for p in range(len(pdf_doc)):
                for xref, *_ in pdf_doc[p].get_images(full=True):
                    img_bytes = pdf_doc.extract_image(xref)["image"]
                    ocr_text  = pytesseract.image_to_string(
                        Image.open(BytesIO(img_bytes)),
                        lang="chi_tra+eng"
                    ).strip()
                    save_image_and_insert(cur, img_bytes, ocr_text,
                                          'ocr_image', filename, page_num=p+1)
        conn.commit()

# ---------- åœ–ç‰‡ä¸Šå‚³è™•ç† ----------------------------------------------------
async def process_photo(img_bytes, original_name):
    ocr_text = pytesseract.image_to_string(
        Image.open(BytesIO(img_bytes)),
        lang="chi_tra+eng"
    ).strip()
    with db_conn() as conn:
        with conn.cursor() as cur:
            save_image_and_insert(cur, img_bytes, ocr_text,
                                  'uploaded_image', original_name)
        conn.commit()

# ---------- æ–‡å­—å•ç­” / ä¿®æ”¹ï¼ˆåªåœ¨ç›¸ç¬¦æ™‚å›åœ–ï¼›ä¸å› OCR æ–‡å­—ï¼‰ -----------------
async def qa_or_modify(user_msg: str, send_text, send_photo):
    # 1) åˆ¤æ–·æ˜¯å¦ç‚ºã€Œä¿®æ”¹ã€æŒ‡ä»¤
    sys_prompt = f"""
ä½ æ˜¯ä¸€å€‹å¹«åŠ©ä½¿ç”¨è€…ä¿®æ”¹è³‡æ–™åº«å…§å®¹çš„åŠ©æ‰‹ã€‚
è«‹åˆ¤æ–·ä»¥ä¸‹è¨Šæ¯æ˜¯å¦è¦ä¿®æ”¹è³‡æ–™ï¼š
ã€Œ{user_msg}ã€
è‹¥éœ€ä¿®æ”¹ï¼Œå›å‚³ï¼š
{{"action":"modify","old_text":"...","new_text":"..."}}
å¦å‰‡å›å‚³ï¼š{{"action":"none"}}
"""
    try:
        j = json.loads(llm.invoke([{"role":"system","content":sys_prompt}]).content)
        if j.get("action") == "modify":
            old_vec_str = vector_to_str(embedding_model.embed_query(j["old_text"]))
            with db_conn() as conn, conn.cursor() as cur:
                cur.execute("SELECT id FROM documents ORDER BY embedding <-> %s LIMIT 1",
                            (old_vec_str,))
                row = cur.fetchone()
                if row:
                    new_vec_str = vector_to_str(embedding_model.embed_query(j["new_text"]))
                    cur.execute("""UPDATE documents
                                   SET content=%s, embedding=%s
                                   WHERE id=%s""",
                                (j["new_text"], new_vec_str, row[0]))
                    conn.commit()
                    await send_text(f"âœ… å·²å°‡ã€Œ{j['old_text']}ã€æ›´æ–°ç‚ºã€Œ{j['new_text']}ã€")
                    return
            await send_text("æ‰¾ä¸åˆ°è¦ä¿®æ”¹çš„å…§å®¹ï¼Œè«‹ç¢ºèªåŸå§‹å…§å®¹æ˜¯å¦å­˜åœ¨")
            return
    except Exception as e:
        print("åˆ¤æ–·ä¿®æ”¹èªå¥å¤±æ•—ï¼š", e)

    # 2) å•ç­”æµç¨‹
    vec = embedding_model.embed_query(user_msg)
    vec_str = vector_to_str(vec)
    
    # 2a) å–å‰ 3 ç­†ç›¸ä¼¼å…§å®¹çµ„æˆ contextï¼ˆå«ä¾†æºè³‡è¨Šï¼‰
    with db_conn() as conn, conn.cursor() as cur:
        cur.execute("""
            SELECT content, filename, page_num, source_type
            FROM documents
            WHERE embedding IS NOT NULL
            ORDER BY embedding <-> %s
            LIMIT 3
        """, (vec_str,))
        top = cur.fetchall()

    context_parts = []
    sources = []
    for content, filename, page_num, source_type in top:
        if content:
            context_parts.append(content)
            src = f"{filename}"
            if page_num: src += f" p.{page_num}"
            if source_type: src += f" ({source_type})"
            sources.append(src)

    context = "\n".join(context_parts)

    # åš´æ ¼åªç”¨ Context å›ç­”
    if not context.strip():
        await send_text("æˆ‘ä¸çŸ¥é“ã€‚ç„¡æ³•åœ¨ä½ æä¾›çš„è³‡æ–™ä¸­æ‰¾åˆ°è¶³å¤ è³‡è¨Šï¼Œè«‹ä¸Šå‚³æˆ–æä¾›æ›´å¤šç›¸é—œå…§å®¹ã€‚")
        return

    answer = llm.invoke([
        {"role": "system", "content": STRICT_SYS_PROMPT},
        {"role": "system", "content": f"Context:\n{context}"},
        {"role": "user",   "content": user_msg}
    ]).content


    # å›è¦†ç­”æ¡ˆ + è³‡æ–™ä¾†æº
    if sources:
        answer += "\n\nğŸ“– è³‡æ–™ä¾†æº:\n" + "\n".join(f"- {s}" for s in sources)

    await send_text(answer)

    # 2b) åªæœ‰åœ¨ç›¸ä¼¼åº¦é”æ¨™æ™‚æ‰å›å‚³åœ–ç‰‡ï¼ˆä¸å«ä»»ä½•æ–‡å­—ï¼‰
    #     ä½¿ç”¨ cosine distance `<=>`ï¼ˆéœ€ pgvector æ”¯æ´ï¼›æœªå»ºç´¢å¼•ä¹Ÿèƒ½åŸ·è¡Œï¼Œä½†è¼ƒæ…¢ï¼‰
    try:
        with db_conn() as conn, conn.cursor() as cur:
            cur.execute(f"""
                SELECT image_ref, (embedding <=> %s) AS dist
                FROM documents
                WHERE image_ref IS NOT NULL
                  AND embedding IS NOT NULL
                ORDER BY dist ASC
                LIMIT {IMG_TOPK}
            """, (vec_str,))
            imgs = cur.fetchall()

        for image_ref, dist in imgs:
            if image_ref and dist is not None and dist <= IMG_SIM_THRESHOLD:
                img_path = os.path.join(IMAGE_DIR, image_ref)
                if os.path.exists(img_path):
                    await send_photo(img_path)   # â† ä¸å‚³ captionï¼Œåªå‚³åœ–ç‰‡
                    break  # åªå›ç¬¬ä¸€å¼µé”æ¨™åœ–
    except Exception as e:
        print("å›å‚³åœ–ç‰‡æµç¨‹éŒ¯èª¤ï¼š", e)

# ---------- Telegram Handler ----------------------------------------------
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = update.message
    if not msg: return

    if msg.text and msg.text.strip() == "/start":
        await msg.reply_text("åˆå§‹åŒ–å®Œæˆï¼Œå¯ä»¥é–‹å§‹ä½¿ç”¨")
        return

    # å°å¹«æ‰‹ï¼šé€åœ–ï¼ˆç¢ºä¿æª”æ¡ˆé—œé–‰ï¼›ä¸å¸¶ captionï¼‰
    async def _send_photo(path):
        try:
            with open(path, "rb") as f:
                await msg.reply_photo(photo=f)
        except Exception as e:
            print("reply_photo å¤±æ•—ï¼š", e)

    # ---------- PDF ----------
    if msg.document and msg.document.mime_type == "application/pdf":
        tg_file = await context.bot.get_file(msg.document.file_id)
        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".pdf")
        await tg_file.download_to_drive(tmp.name)
        tmp.close()
        await process_pdf(tmp.name)
        await msg.reply_text("âœ… PDF å·²å„²å­˜ä¸¦è™•ç†")
        return

    # ---------- Photo ----------
    if msg.photo:
        tg_file = await context.bot.get_file(msg.photo[-1].file_id)
        bio = BytesIO()
        await tg_file.download_to_memory(out=bio)
        img_bytes = bio.getvalue()
        await process_photo(img_bytes, f"{msg.photo[-1].file_id}.jpg")
        await msg.reply_text("âœ… åœ–ç‰‡å·²è™•ç†ä¸¦å¯«å…¥è³‡æ–™åº«")
        return

    # ---------- Text ----------
    if msg.text:
        await qa_or_modify(msg.text.strip(), msg.reply_text, _send_photo)
        return

# ---------- Bot å•Ÿå‹• -------------------------------------------------------
app = ApplicationBuilder().token(BOT_TOKEN).build()
app.add_handler(MessageHandler(filters.ALL, handle_message))
app.run_polling()
